{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tutorial section 1, we walked through how to create and apply operations to AD instances and AD instances arrays. Based on that, we will demon how to use `boomdiff.optimize` to run gradient-based optimizers, and how to use some pre-set loss functions in `boomdiff.loss_function` to make life easier.\n",
    "\n",
    "Our optimizers in `boomdiff.optimize` has a key advantage over optimizers in current popular pacakages like [`pytorch`](https://pytorch.org/docs/stable/optim.html): flexibility. As all the parameters are denoted by name strings, we can determine which parameters we want to update at each iteration without initializing the whole optimizer instance. This makes some mean-field assumption based algorithms, like [Coordinate descent](https://en.wikipedia.org/wiki/Coordinate_descent), much more easier to implement in `boomdiff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boomdiff import AD, optimize, loss_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Optimize with respect to scalar AD instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we want to minimize:\n",
    "\n",
    "$$f = a^2 + b^2, \\quad a,b \\in \\mathbb{R}$$\n",
    "\n",
    "we know the optimization results should be $\\hat{a} \\approx 0, \\hat{b} \\approx 0, f_{min} \\approx 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize two variables `a` and `b`, at their staring points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AD(-7, 'a')\n",
    "b = AD(4, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the target loss function we want to minimize. \n",
    "\n",
    "> **loss should be a callable without arguments, this can be easily done with `lambda` syntax sugar in python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda: a**2 + b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: -7, b: 4, loss: 65\n"
     ]
    }
   ],
   "source": [
    "print(f\"a: {a.value()}, b: {b.value()}, loss: {loss().value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Initialize an optimizer\n",
    "\n",
    "At the moment, we support three optimizers: `optimize.GD`([gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)), `optimize.Momentum`([momentum](https://medium.com/analytics-vidhya/momentum-a-simple-yet-efficient-optimizing-technique-ef76834e4423)), `optimize.Adam`([Adam](https://arxiv.org/pdf/1412.6980.pdf)). They share the similar APIs (for a complet API, check [here](https://github.com/team-boomeraang/cs107-FinalProject/blob/master/docs/documentation.md#optimization-methods-optimizer-subclasses)). \n",
    "\n",
    "I will use the Adam as an example here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimize.Adam(learning_rate=0.1, betas=(0.9, 0.999), eps=1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to mention here, the construction of our optimizer makes it decoupled from the parameters, which results in the flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the optimizer to update\n",
    "\n",
    "There are two ways to update the variables: `step` will update for only one step, and `minimize` can set the step numbers you want to update. Their API are nearly the same. \n",
    "\n",
    "> The optimizer will update the variable\n",
    "\n",
    "The `record` flag (determine whether you want to record the loss track) is set to `False` by default, to avoid unintended memory occupying. But we will set to `True` mannully here, to demon the loss-iteration curve at the end. \n",
    "\n",
    "Besides, as we mentioned above, we can freely determine the parameters we want to update without re-initialize the optimizer (This is important because you will loss the history used in history-related algorithms like Adam and Momentum, if you reinitialize the optimizer).\n",
    "\n",
    "we can update `a` and `b` together, for one step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step(loss, [a,b], record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: -6.9000000000714286, b: 3.900000000125, loss: 62.820000001960715\n"
     ]
    }
   ],
   "source": [
    "print(f\"a: {a.value()}, b: {b.value()}, loss: {loss().value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can update `a` only for one step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step(loss, [a], record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: -6.765669988048683, b: 3.900000000125, loss: 60.98429038815767\n"
     ]
    }
   ],
   "source": [
    "print(f\"a: {a.value()}, b: {b.value()}, loss: {loss().value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or update `b` only for one step: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step(loss, [b], record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: -6.765669988048683, b: 3.7657155487753675, loss: 59.95490398147123\n"
     ]
    }
   ],
   "source": [
    "print(f\"a: {a.value()}, b: {b.value()}, loss: {loss().value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or update `a` and `b` for 500 steps with `minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.minimize(loss, [a,b], steps=500, record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: -9.181156714018847e-12, b: 9.537149048472307e-13, loss: 8.520321072710111e-23\n"
     ]
    }
   ],
   "source": [
    "print(f\"a: {a.value()}, b: {b.value()}, loss: {loss().value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the results are close to our expectation. We can draw the loss-iteration curve by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt.plot_loss_func() #This only works when you set record=True in all previous updates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Optimize with respect to AD instances arrays\n",
    "\n",
    "The idea and procedure is similar. Let's say we are going to minimize the Frobinius norm of a 3*3 matrix W:\n",
    "\n",
    "$$\\min F_n = \\sum_{ij}W_{ij}^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = AD.from_array(np.random.randint(-10,10, size=(3,3)), prefix=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda: AD.sum(W**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial W:\n",
      "[[ 1.  2. -3.]\n",
      " [-4.  0.  0.]\n",
      " [ 6. -2.  3.]]\n",
      "Initial loss:  79\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial W:\")\n",
    "print(AD.to_array(W).round(3))\n",
    "print(\"Initial loss: \", loss().round(3).value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_arr = optimize.Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call the `step` or `minimize` to update. `var_list` arguments only need to be 1D list or array of parameters, no order required. Because the parameters are denoted by unique name string. You can even concatenate different list of parameters as `var_list`, as long as all parameters appear in the `loss` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_arr.minimize(loss, W.reshape(-1), steps=500, record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized W:\n",
      "[[ 0. -0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0. -0.]]\n",
      "Final loss:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimized W:\")\n",
    "print(AD.to_array(W).round(3))\n",
    "print(\"Final loss: \", loss().round(3).value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the loss-iteration curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_arr.plot_loss_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Pre-set loss functions\n",
    "\n",
    "As we can see above, user can define customized loss functions to optimize with `boomdiff`, which enabled broader user cases. For convinience and educational purpose, in particular, we have included the API for two common loss functions: mean squared error in the context of a linear model (`loss_functions.linear_mse()`) and binary cross-entropy for a logistic model (`loss_functions.logistic_cross_entropy`). Importantly, these two loss functions make fairly strong assumptions regarding the functional form of the data. Thus, we have titled the functions to inform the user of their purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) `linear_mse` loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a review of mean squared error, the loss function takes the form:\n",
    "\n",
    "$$\\sum_{i=1}^n (y_i - \\hat{y_i})^2$$\n",
    "\n",
    "for some observed outcome, $y_i$ and prediction of an arbitrary model, $\\hat{y_i}$. In this case, we will restrict the functional form of the model to be linear, as is the case of linear regression (and hence the name linear_mse()). That is, we assume:\n",
    "\n",
    "$$y_i = \\beta_1 x_1 + ... + \\beta_p x_p + \\epsilon_i$$\n",
    "\n",
    "where $\\epsilon_i$ is assumed to be Gaussian noise. Please also note that we will not be estimating an intercept in this case. For that to be included, the row of value 1 will be needed to be added to the design matrix for use in this function. With this in mind, our loss function takes the form:\n",
    "\n",
    "$$f(\\beta_1, ... \\beta_p) = \\sum_{i=1}^n (y_i - (\\beta_1x_1 + ... + \\beta_p x_p))^2$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) `logistic_cross_entropy` loss functions\n",
    "\n",
    "This loss function is featured in logistic binary regression models: we have $N$ observed data $X^k$ with $M$ different features, each observation has a binary classification label $y^k$. We would like to find a set of feature weights $\\beta$ and a bias $b$, to minimize the cross entropy loss, the second equation: \n",
    "\n",
    "$$\\hat{y}^k = \\text{logistic}(b+\\beta_0X_0^k + \\beta_1X_1^k + \\dots + \\beta_{M-1}X_{M-1}^k)$$\n",
    "\n",
    "$$\\text{arg min}_{\\beta,b}[- \\frac{1}{N}\\sum_{k=1}^N(y^k\\log(\\hat{y}^k) + (1-y^k)\\log (1- \\hat{y}^k))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate the two kinds of loss functions in tutorial section 3 and section 4, by examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
